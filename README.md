# basic-ML-programming-project

This is a code snippet for a small ML project.

Our objective is to create a simple machine learning algorithm based on policy and value iteration.
The given problem is to find a path to navigate a 2D grid-maze with empty tiles, hazards, and walls
in order to reach a given ending point using as few moves as possible. I have presented two solution
algorithms here; both attempt to take advantage of dynamic programming to find a solution path.

Value Iteration
This algorithm simply creates a 2D array with a grid that maps exactly with the input grid-maze
where each traversible square is assigned a utility value based on the Bellman equation. Walls
are initialized a utility of 0, hazards are -1, and the exit is 1. The path is generated by
the agent greedily choosing the highest utility square among its
neighbors to move to next.

Policy Iteration
This algorithm returns a general policy for each traversible value of the grid, meaning that the final
output "map" has directions instead of preference values corresponding to each traversible square's neighbors.
Because the dataset the algorithm works with is finite and discrete (four directions vs decimal values)
the convergence and runtime for this algorithm is far superior. Initial policy for the grid is completely
random.
